
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="author" content="guchio3" />
        <meta name="keywords" content="Theano,Machine Learning" />
        <meta name="description" content="Theano の速度を改良した際のメモ" />


    <title>Speeding Up Theano - guchiBLO</title>

        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css" />

    <link href="/theme/css/font-awesome.min.css" rel="stylesheet" />
    <link href="/theme/css/pygments/native.css" rel="stylesheet" />
    
    <link href="/theme/css/pelican-twitchy.min.css" rel="stylesheet" />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <!-- Feeds -->
</head>
<body data-spy="scroll" data-target="#scrollspy">
    <div id="wrapper">
        <!-- Sidebar -->
        <div id="sidebar-wrapper-small" class="twitchy-background">
            <ul id="accordion-small" class="sidebar-nav sidebar-nav-small">
                <li>
        <a href="" title="guchiBLO" class="collapsed">
            <span class="glyphicon glyphicon-home"></span>
        </a>
    </li>
                <li class="nav-divider"></li>
                <li>
        <a href="/archives.html" title="Recent Articles" class="collapsed">
            <span class="glyphicon glyphicon-th-list"></span>
        </a>
    </li>
                
                <li class="nav-divider"></li>
                <li>
                    <a data-toggle="collapse" data-parent="#accordion-small" href="#collapse-social-small" title="Social" class="collapsed">
                        <i class="fa fa-users padding-small"></i>
                    </a>
                </li>
                <li class="panel anti-panel"><ul id="collapse-social-small" class="collapse ">
                    <li>
                        <a href="https://github.com/guchio3" title="github"><i class="fa fa-github-square fa-lg padding-small"></i></a>
                    </li>
                    <li>
                        <a href="https://twitter.com/ihcgT_Ykchi" title="twitter"><i class="fa fa-twitter-square fa-lg padding-small"></i></a>
                    </li>
                </ul></li>
                <li class="nav-divider"></li>
                <li>
        <a href="#" title="Back to top" class="collapsed">
            <span class="fa fa-arrow-up"></span>
        </a>
    </li>
            </ul>
        </div>
        <div id="sidebar-wrapper" class="twitchy-background">
            <ul id="accordion" class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/">
<img src="//images/siteBaseImages/guchiBLO_temp.png" width="200" alt="Sitelogo"/>                     </a>
                </li>
                    <li>
                        <a href="/archives.html">
                            <span class="glyphicon glyphicon-th-list padding-small"></span>
                            Recent Articles
                        </a>
                    </li>
                <li class="nav-divider"></li>
                <li>
                    <a data-toggle="collapse" data-parent="#accordion" href="#collapse-social">
                        <i class="fa fa-users padding-small"></i>
                        Contact
                    </a>
                </li>
                <li class="panel anti-panel"><ul id="collapse-social" class="sidebar_submenu collapse ">
                    <li>
                        <a href="https://github.com/guchio3" title="github">
                            <i class="fa fa-github-square fa-lg padding-small"></i>
                            github
                        </a>
                    </li>
                    <li>
                        <a href="https://twitter.com/ihcgT_Ykchi" title="twitter">
                            <i class="fa fa-twitter-square fa-lg padding-small"></i>
                            twitter
                        </a>
                    </li>
                </ul></li>
                
                <li class="nav-divider"></li>
                <li>
                    <a data-toggle="collapse" data-parent="#accordion" href="#collapse-pages">
                        <i class="fa fa-folder-open padding-small"></i>
                        Pages
                    </a>
                </li>
                <li class="panel anti-panel"><ul id="collapse-pages" class="sidebar_submenu collapse ">
                    <li>
                        <a href="/pages/AUTHOR.html">
                            <i class="fa fa-file-text padding-small"></i>
                            AUTHOR
                        </a>
                    </li>
                    <li>
                        <a href="/pages/CONTENTS.html">
                            <i class="fa fa-file-text padding-small"></i>
                            CONTENTS
                        </a>
                    </li>
                </ul></li>
                
                <li class="nav-divider"></li>
                <li>
                    <a data-toggle="collapse" data-parent="#accordion" href="#collapse-categories">
                        <i class="fa fa-folder-open padding-small"></i>
                        Categories
                    </a>
                </li>
                <li class="panel anti-panel"><ul id="collapse-categories" class="sidebar_submenu collapse ">
                    <li class="active">
                        <a href="/category/programming.html">
                            <i class="fa fa-folder-open padding-small"></i>
                            Programming
                            <span class="badge pull-right categorybadge">2</span>
                        </a>
                    </li>
                </ul></li>
                
            </ul>
        </div>
        <!-- /#sidebar-wrapper -->
        <!-- open/close sidebar -->
        <a href="#menu-toggle" class="btn btn-default" id="menu-toggle">
            <span id="right-arrow" class="glyphicon glyphicon-chevron-right"  title="expand sidebar"></span>
            <span id="left-arrow" class="glyphicon glyphicon-chevron-left" title="minimize sidebar"></span>
        </a>
       <!-- /open/close sidebar -->

        <!-- Page Content -->
        <div id="page-content-wrapper">
            <div class="container-fluid">
<section id="content">
    <article>
        <div class="row">
            <div class="col-lg-9">
                <header class="page-header">
                    <h1>
                        <a href="/Speeding_Up_Theano.html"
                           rel="bookmark"
                           title="Permalink to Speeding Up Theano">
                            Speeding Up Theano
                        </a>
                        <small>
<div class="post-info">
    <div class="publish-info-block">
        <small>
            <span class="published">
                <i class="fa fa-calendar padding-small"></i><time datetime="2017-10-10T19:00:00+09:00"> 火 10 10月 2017</time>
            </span>
            <span class="category">
                <i class="fa fa-folder-open padding-small"></i><a href="/category/programming.html">Programming</a>
            </span>
            <span class="tags">
                <i class="fa fa-tags padding-small"></i>
                <a href="/tag/theano.html">Theano</a> /                 <a href="/tag/machine-learning.html">Machine Learning</a>            </span>
        </small>
    </div>
</div><!-- /.post-info -->                        </small>
                    </h1>
                </header>
            </div>
        </div>
        <div class="row">
            <div class="col-lg-9">
                <div class="entry-content">
                    <h1>Outline</h1>
<p>Theano の速度向上のため行ったことをメモ。</p>
<p>なお、使用した Theano のバージョンは 0.8.2 であり、os 情報は以下の通り。</p>
<div class="highlight"><pre><span></span>$ cat /proc/version
Linux version <span class="m">4</span>.4.0-93-generic <span class="o">(</span>buildd@lgw01-03<span class="o">)</span> <span class="o">(</span>gcc version <span class="m">5</span>.4.0 <span class="m">20160609</span> <span class="o">(</span>Ubuntu <span class="m">5</span>.4.0-6ubuntu1~16.04.4<span class="o">)</span> <span class="o">)</span> <span class="c1">#116-Ubuntu SMP Fri Aug 11 21:17:51 UTC 2017</span>
</pre></div>


<hr>
<h1>Profile the program</h1>
<p>Theano には <a href="http://deeplearning.net/software/theano_versions/0.8.X/tutorial/profiling.html">profile 機能</a>があり、どの部分が速度上 (他メモリ使用量なども確認できる) のボトルネックかを簡単に確認できる。<br>
目的によって様々な利用法があるが、私は以下のように利用した。</p>
<p>まず、プログラム内で </p>
<div class="highlight"><pre><span></span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">profile</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>


<p>とする。これにより theano.config が設定できる。<a href="http://deeplearning.net/software/theano_versions/0.8.X/library/config.html?highlight=profile#config.profile">なお theano.config の状態は以下のコマンドで確認すれば良い。</a></p>
<div class="highlight"><pre><span></span>$ python -c <span class="s1">&#39;import theano; print(theano.config)&#39;</span> <span class="p">|</span> less
</pre></div>


<p>私の場合、<strong>系列データを扱う Neural Network </strong>を実装しており、これの学習を扱う theano.function である train_fn が計算量のボトルネックなことが明らかだったため、<a href="http://deeplearning.net/software/theano_versions/0.8.X/tutorial/profiling.html">Profiling Theano function</a> を参考に theano.function の profile.print_summary() を利用して以下のように profiling を行った。</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">train_fn</span><span class="o">.</span><span class="n">profile</span><span class="o">.</span><span class="n">print_summary</span><span class="p">())</span>
</pre></div>


<p>以下が結果の一部。</p>
<div class="highlight"><pre><span></span>Function <span class="nv">profiling</span>
<span class="o">==================</span>
  Message: examples/run_tasks.py:376
  Time in <span class="m">100</span> calls to Function.__call__: <span class="m">5</span>.591766e+01s
  Time in Function.fn.__call__: <span class="m">5</span>.585304e+01s <span class="o">(</span><span class="m">99</span>.884%<span class="o">)</span>
  Time in thunks: <span class="m">5</span>.549018e+01s <span class="o">(</span><span class="m">99</span>.236%<span class="o">)</span>
  Total compile time: <span class="m">9</span>.343460e+02s
    Number of Apply nodes: <span class="m">1288</span>
    Theano Optimizer time: <span class="m">8</span>.834189e+02s
       Theano validate time: <span class="m">2</span>.949661e+00s
    Theano Linker <span class="nb">time</span> <span class="o">(</span>includes C, CUDA code generation/compiling<span class="o">)</span>: <span class="m">4</span>.475670e+01s
       Import <span class="nb">time</span> <span class="m">3</span>.738601e-01s

Time in all call to theano.grad<span class="o">()</span> <span class="m">2</span>.802125e+01s
Time since theano import <span class="m">1045</span>.185s
Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">99</span>.0%    <span class="m">99</span>.0%      <span class="m">54</span>.942s       <span class="m">2</span>.75e-01s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.scan_module.scan_op.Scan
   <span class="m">0</span>.4%    <span class="m">99</span>.5%       <span class="m">0</span>.243s       <span class="m">3</span>.55e-06s     C    <span class="m">68500</span>     <span class="m">685</span>   theano.tensor.elemwise.Elemwise
   <span class="m">0</span>.2%    <span class="m">99</span>.6%       <span class="m">0</span>.095s       <span class="m">9</span>.54e-05s     Py    <span class="m">1000</span>      <span class="m">10</span>   theano.tensor.blas.Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.7%       <span class="m">0</span>.053s       <span class="m">6</span>.93e-06s     C     <span class="m">7600</span>      <span class="m">76</span>   theano.tensor.basic.Alloc
   <span class="m">0</span>.1%    <span class="m">99</span>.8%       <span class="m">0</span>.033s       <span class="m">3</span>.25e-04s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxWithBias
   <span class="m">0</span>.1%    <span class="m">99</span>.8%       <span class="m">0</span>.028s       <span class="m">9</span>.45e-05s     Py     <span class="m">300</span>       <span class="m">3</span>   theano.tensor.blas.Gemm
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.014s       <span class="m">7</span>.81e-07s     C    <span class="m">17300</span>     <span class="m">173</span>   theano.compile.ops.Shape_i
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.011s       <span class="m">8</span>.60e-06s     C     <span class="m">1300</span>      <span class="m">13</span>   theano.tensor.basic.Join
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.010s       <span class="m">2</span>.72e-06s     C     <span class="m">3600</span>      <span class="m">36</span>   theano.tensor.basic.Reshape
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.010s       <span class="m">1</span>.19e-05s     C      <span class="m">800</span>       <span class="m">8</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.008s       <span class="m">1</span>.13e-06s     C     <span class="m">7500</span>      <span class="m">75</span>   theano.tensor.subtensor.Subtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.007s       <span class="m">1</span>.03e-06s     C     <span class="m">7100</span>      <span class="m">71</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.006s       <span class="m">3</span>.20e-05s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.006s       <span class="m">7</span>.98e-07s     C     <span class="m">7700</span>      <span class="m">77</span>   theano.tensor.opt.MakeVector
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.006s       <span class="m">5</span>.55e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.004s       <span class="m">3</span>.89e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.basic.Nonzero
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.004s       <span class="m">3</span>.73e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxGrad
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">1</span>.69e-05s     C      <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor1
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">6</span>.30e-06s     C      <span class="m">400</span>       <span class="m">4</span>   theano.tensor.elemwise.Sum
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.001s       <span class="m">6</span>.83e-07s     C     <span class="m">1700</span>      <span class="m">17</span>   theano.tensor.basic.ScalarFromTensor
   ... <span class="o">(</span>remaining <span class="m">5</span> Classes account <span class="k">for</span>   <span class="m">0</span>.01%<span class="o">(</span><span class="m">0</span>.00s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
  <span class="m">87</span>.7%    <span class="m">87</span>.7%      <span class="m">48</span>.643s       <span class="m">4</span>.86e-01s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}</span>
  <span class="m">11</span>.4%    <span class="m">99</span>.0%       <span class="m">6</span>.300s       <span class="m">6</span>.30e-02s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,scan_fn<span class="o">}</span>
   <span class="m">0</span>.2%    <span class="m">99</span>.2%       <span class="m">0</span>.095s       <span class="m">9</span>.54e-05s     Py    <span class="m">1000</span>       <span class="m">10</span>   Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.053s       <span class="m">6</span>.93e-06s     C     <span class="m">7600</span>       <span class="m">76</span>   Alloc
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.033s       <span class="m">5</span>.49e-06s     C     <span class="m">6000</span>       <span class="m">60</span>   Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.4%       <span class="m">0</span>.033s       <span class="m">3</span>.25e-04s     C      <span class="m">100</span>        <span class="m">1</span>   SoftmaxWithBias
   <span class="m">0</span>.1%    <span class="m">99</span>.4%       <span class="m">0</span>.029s       <span class="m">2</span>.56e-06s     C     <span class="m">11300</span>      <span class="m">113</span>   Elemwise<span class="o">{</span>Add<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.5%       <span class="m">0</span>.028s       <span class="m">9</span>.45e-05s     Py     <span class="m">300</span>        <span class="m">3</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.6%       <span class="m">0</span>.028s       <span class="m">4</span>.77e-06s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.024s       <span class="m">4</span>.11e-06s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.020s       <span class="m">2</span>.91e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.020s       <span class="m">1</span>.95e-04s     C      <span class="m">100</span>        <span class="m">1</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.019s       <span class="m">2</span>.74e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.018s       <span class="m">2</span>.83e-06s     C     <span class="m">6200</span>       <span class="m">62</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.011s       <span class="m">8</span>.60e-06s     C     <span class="m">1300</span>       <span class="m">13</span>   Join
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.011s       <span class="m">1</span>.33e-05s     C      <span class="m">800</span>        <span class="m">8</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.009s       <span class="m">3</span>.28e-06s     C     <span class="m">2700</span>       <span class="m">27</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.008s       <span class="m">6</span>.85e-06s     C     <span class="m">1100</span>       <span class="m">11</span>   Elemwise<span class="o">{</span>clip,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.007s       <span class="m">9</span>.06e-07s     C     <span class="m">7500</span>       <span class="m">75</span>   Shape_i<span class="o">{</span><span class="m">0</span><span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.007s       <span class="m">6</span>.60e-05s     C      <span class="m">100</span>        <span class="m">1</span>   IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>:int64:<span class="o">}</span>
   ... <span class="o">(</span>remaining <span class="m">109</span> Ops account <span class="k">for</span>   <span class="m">0</span>.17%<span class="o">(</span><span class="m">0</span>.10s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
  <span class="m">87</span>.7%    <span class="m">87</span>.7%      <span class="m">48</span>.643s       <span class="m">4</span>.86e-01s    <span class="m">100</span>   <span class="m">783</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>. <span class="m">0</span>, Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2,3,x<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int6
  <span class="m">11</span>.4%    <span class="m">99</span>.0%       <span class="m">6</span>.300s       <span class="m">6</span>.30e-02s    <span class="m">100</span>   <span class="m">688</span>   forall_inplace,cpu,scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>.0, Subtensor<span class="o">{</span>int64:int64:int8<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, controller.W_in_and_reads_to_o01, controller.W_hid_to_o01, controller.W_in_and_reads_to_i01, controller.W_hid_to_i01, controller.W_in_and_rea
   <span class="m">0</span>.1%    <span class="m">99</span>.1%       <span class="m">0</span>.033s       <span class="m">3</span>.25e-04s    <span class="m">100</span>   <span class="m">723</span>   SoftmaxWithBias<span class="o">(</span>Dot22.0, output_modality_net.b<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.020s       <span class="m">1</span>.95e-04s    <span class="m">100</span>   <span class="m">733</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}(</span>Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.014s       <span class="m">1</span>.42e-04s    <span class="m">100</span>   <span class="m">716</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, output_modality_net.W<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.012s       <span class="m">1</span>.18e-04s    <span class="m">100</span>   <span class="m">907</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.012s       <span class="m">1</span>.17e-04s    <span class="m">100</span>   <span class="m">764</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, SoftmaxGrad.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.011s       <span class="m">1</span>.11e-04s    <span class="m">100</span>   <span class="m">912</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.011s       <span class="m">1</span>.07e-04s    <span class="m">100</span>   <span class="m">765</span>   Dot22<span class="o">(</span>SoftmaxGrad.0, output_modality_net.W.T<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.011s       <span class="m">1</span>.05e-04s    <span class="m">100</span>   <span class="m">491</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>. <span class="m">0</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.010s       <span class="m">1</span>.05e-04s    <span class="m">100</span>   <span class="m">487</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.010s       <span class="m">1</span>.04e-04s    <span class="m">100</span>   <span class="m">1236</span>   Gemm<span class="o">{</span>inplace<span class="o">}(</span>Alloc.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">})</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.009s       <span class="m">9</span>.34e-05s    <span class="m">100</span>   <span class="m">1237</span>   Gemm<span class="o">{</span>inplace<span class="o">}(</span>Alloc.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">})</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.009s       <span class="m">9</span>.30e-05s    <span class="m">100</span>   <span class="m">914</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.009s       <span class="m">9</span>.14e-05s    <span class="m">100</span>   <span class="m">916</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.009s       <span class="m">8</span>.63e-05s    <span class="m">100</span>   <span class="m">1238</span>   Gemm<span class="o">{</span>inplace<span class="o">}(</span>Alloc.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">})</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.007s       <span class="m">7</span>.35e-05s    <span class="m">100</span>   <span class="m">1103</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.4%       <span class="m">0</span>.007s       <span class="m">6</span>.60e-05s    <span class="m">100</span>   <span class="m">918</span>   IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>:int64:<span class="o">}(</span>Alloc.0, Subtensor<span class="o">{</span>::int64<span class="o">}</span>.0, ScalarFromTensor.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.4%       <span class="m">0</span>.006s       <span class="m">6</span>.28e-05s    <span class="m">100</span>   <span class="m">1257</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i0 * i1 * sgn<span class="o">(</span>i2<span class="o">)))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.4%       <span class="m">0</span>.006s       <span class="m">5</span>.62e-05s    <span class="m">100</span>    <span class="m">74</span>   Join<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, read0.read0.shift.W, read1.read1.shift.W, read2.read2.shift.W, read3.read3.shift.W<span class="o">)</span>
   ... <span class="o">(</span>remaining <span class="m">1268</span> Apply instances account <span class="k">for</span> <span class="m">0</span>.62%<span class="o">(</span><span class="m">0</span>.34s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and <span class="nb">set</span> the Theano flag lib.amdlibm<span class="o">=</span>True. This speeds up only some Elemwise operation.

    .
    .
    .
</pre></div>


<p>この結果より、私のプログラムの速度が遅い一番の原因は系列データを扱う際に利用している scan_fn 内において grad を計算する部分だと言うことが分かる。profile には grad_of_scan_fn の詳細も記載されており、私の場合以下のようになっていた。</p>
<div class="highlight"><pre><span></span>Scan Op profiling <span class="o">(</span> grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn <span class="o">)</span>
<span class="o">==================</span>
  Message: None
  Time in <span class="m">100</span> calls of the op <span class="o">(</span><span class="k">for</span> a total of <span class="m">8671</span> steps<span class="o">)</span> <span class="m">4</span>.828692e+01s

  Total <span class="nb">time</span> spent in calling the VM <span class="m">4</span>.562579e+01s <span class="o">(</span><span class="m">94</span>.489%<span class="o">)</span>
  Total overhead <span class="o">(</span>computing slices..<span class="o">)</span> <span class="m">2</span>.661133e+00s <span class="o">(</span><span class="m">5</span>.511%<span class="o">)</span>

Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">20</span>.5%    <span class="m">20</span>.5%       <span class="m">8</span>.227s       <span class="m">2</span>.43e-06s     C   <span class="m">3390361</span>     <span class="m">391</span>   theano.tensor.elemwise.Elemwise
  <span class="m">13</span>.1%    <span class="m">33</span>.7%       <span class="m">5</span>.250s       <span class="m">6</span>.05e-05s     C    <span class="m">86710</span>      <span class="m">10</span>   theano.tensor.nnet.conv.ConvOp
  <span class="m">13</span>.1%    <span class="m">46</span>.7%       <span class="m">5</span>.229s       <span class="m">1</span>.21e-05s     Py  <span class="m">433550</span>      <span class="m">50</span>   theano.tensor.blas.Dot22
  <span class="m">12</span>.4%    <span class="m">59</span>.2%       <span class="m">4</span>.985s       <span class="m">3</span>.59e-05s     Py  <span class="m">138736</span>      <span class="m">16</span>   theano.tensor.basic.Split
   <span class="m">7</span>.3%    <span class="m">66</span>.4%       <span class="m">2</span>.914s       <span class="m">2</span>.24e-05s     Py  <span class="m">130065</span>      <span class="m">15</span>   theano.tensor.blas.BatchedDot
   <span class="m">4</span>.8%    <span class="m">71</span>.2%       <span class="m">1</span>.914s       <span class="m">2</span>.76e-05s     Py   <span class="m">69368</span>       <span class="m">8</span>   theano.tensor.blas.Gemv
   <span class="m">3</span>.6%    <span class="m">74</span>.8%       <span class="m">1</span>.433s       <span class="m">1</span>.18e-06s     C   <span class="m">1213940</span>     <span class="m">140</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">3</span>.4%    <span class="m">78</span>.2%       <span class="m">1</span>.379s       <span class="m">2</span>.48e-06s     C   <span class="m">554944</span>      <span class="m">64</span>   theano.tensor.elemwise.Sum
   <span class="m">3</span>.1%    <span class="m">81</span>.3%       <span class="m">1</span>.235s       <span class="m">1</span>.26e-06s     C   <span class="m">979823</span>     <span class="m">113</span>   theano.tensor.basic.Reshape
   <span class="m">3</span>.0%    <span class="m">84</span>.3%       <span class="m">1</span>.191s       <span class="m">2</span>.29e-05s     Py   <span class="m">52026</span>       <span class="m">6</span>   theano.tensor.blas.Gemm
   <span class="m">2</span>.8%    <span class="m">87</span>.1%       <span class="m">1</span>.105s       <span class="m">3</span>.19e-05s     Py   <span class="m">34684</span>       <span class="m">4</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">2</span>.7%    <span class="m">89</span>.8%       <span class="m">1</span>.097s       <span class="m">1</span>.58e-05s     Py   <span class="m">69368</span>       <span class="m">8</span>   theano.tensor.blas.Dot22Scalar
   <span class="m">1</span>.7%    <span class="m">91</span>.5%       <span class="m">0</span>.689s       <span class="m">1</span>.07e-06s     C   <span class="m">641654</span>      <span class="m">74</span>   theano.tensor.subtensor.Subtensor
   <span class="m">1</span>.2%    <span class="m">92</span>.7%       <span class="m">0</span>.476s       <span class="m">2</span>.74e-05s     Py   <span class="m">17342</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">1</span>.1%    <span class="m">93</span>.8%       <span class="m">0</span>.439s       <span class="m">3</span>.38e-06s     C   <span class="m">130065</span>      <span class="m">15</span>   theano.tensor.basic.Join
   <span class="m">0</span>.9%    <span class="m">94</span>.7%       <span class="m">0</span>.349s       <span class="m">9</span>.57e-07s     C   <span class="m">364182</span>      <span class="m">42</span>   theano.compile.ops.Shape_i
   <span class="m">0</span>.9%    <span class="m">95</span>.5%       <span class="m">0</span>.347s       <span class="m">9</span>.99e-06s     C    <span class="m">34684</span>       <span class="m">4</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">0</span>.8%    <span class="m">96</span>.4%       <span class="m">0</span>.339s       <span class="m">9</span>.77e-06s     C    <span class="m">34684</span>       <span class="m">4</span>   theano.tensor.nnet.nnet.Softmax
   <span class="m">0</span>.7%    <span class="m">97</span>.1%       <span class="m">0</span>.286s       <span class="m">8</span>.90e-07s     C   <span class="m">320827</span>      <span class="m">37</span>   theano.tensor.opt.MakeVector
   <span class="m">0</span>.6%    <span class="m">97</span>.7%       <span class="m">0</span>.229s       <span class="m">1</span>.32e-05s     Py   <span class="m">17342</span>       <span class="m">2</span>   theano.tensor.basic.ARange
   ... <span class="o">(</span>remaining <span class="m">8</span> Classes account <span class="k">for</span>   <span class="m">2</span>.33%<span class="o">(</span><span class="m">0</span>.93s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
  <span class="m">13</span>.1%    <span class="m">13</span>.1%       <span class="m">5</span>.229s       <span class="m">1</span>.21e-05s     Py    <span class="m">433550</span>       <span class="m">50</span>   Dot22
   <span class="m">7</span>.8%    <span class="m">20</span>.8%       <span class="m">3</span>.118s       <span class="m">3</span>.60e-05s     Py    <span class="m">86710</span>       <span class="m">10</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}</span>
   <span class="m">7</span>.3%    <span class="m">28</span>.1%       <span class="m">2</span>.914s       <span class="m">2</span>.24e-05s     Py    <span class="m">130065</span>       <span class="m">15</span>   BatchedDot
   <span class="m">4</span>.8%    <span class="m">32</span>.9%       <span class="m">1</span>.928s       <span class="m">1</span>.11e-04s     C     <span class="m">17342</span>        <span class="m">2</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;valid&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, True<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, False<span class="o">)}</span>
   <span class="m">4</span>.8%    <span class="m">37</span>.7%       <span class="m">1</span>.903s       <span class="m">1</span>.10e-04s     C     <span class="m">17342</span>        <span class="m">2</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;full&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, False<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, True<span class="o">)}</span>
   <span class="m">4</span>.7%    <span class="m">42</span>.3%       <span class="m">1</span>.867s       <span class="m">3</span>.59e-05s     Py    <span class="m">52026</span>        <span class="m">6</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">4</span>.4%    <span class="m">46</span>.8%       <span class="m">1</span>.775s       <span class="m">2</span>.44e-06s     C     <span class="m">728364</span>       <span class="m">84</span>   Elemwise<span class="o">{</span>mul,no_inplace<span class="o">}</span>
   <span class="m">4</span>.3%    <span class="m">51</span>.1%       <span class="m">1</span>.717s       <span class="m">2</span>.42e-06s     C     <span class="m">711022</span>       <span class="m">82</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">3</span>.4%    <span class="m">54</span>.4%       <span class="m">1</span>.352s       <span class="m">3</span>.12e-05s     Py    <span class="m">43355</span>        <span class="m">5</span>   Gemv<span class="o">{</span>no_inplace<span class="o">}</span>
   <span class="m">3</span>.0%    <span class="m">57</span>.4%       <span class="m">1</span>.191s       <span class="m">2</span>.29e-05s     Py    <span class="m">52026</span>        <span class="m">6</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">2</span>.8%    <span class="m">60</span>.2%       <span class="m">1</span>.105s       <span class="m">3</span>.19e-05s     Py    <span class="m">34684</span>        <span class="m">4</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>
   <span class="m">2</span>.7%    <span class="m">62</span>.9%       <span class="m">1</span>.097s       <span class="m">1</span>.58e-05s     Py    <span class="m">69368</span>        <span class="m">8</span>   Dot22Scalar
   <span class="m">1</span>.9%    <span class="m">64</span>.8%       <span class="m">0</span>.753s       <span class="m">8</span>.68e-05s     C     <span class="m">8671</span>        <span class="m">1</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;va lid&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, <span class="m">2</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, False<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, True<span class="o">)}</span>
   <span class="m">1</span>.8%    <span class="m">66</span>.6%       <span class="m">0</span>.707s       <span class="m">1</span>.15e-06s     C     <span class="m">615641</span>       <span class="m">71</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">1</span>.6%    <span class="m">68</span>.2%       <span class="m">0</span>.637s       <span class="m">2</span>.23e-06s     C     <span class="m">286143</span>       <span class="m">33</span>   Sum<span class="o">{</span><span class="nv">axis</span><span class="o">=[</span><span class="m">2</span><span class="o">]</span>, <span class="nv">acc_dtype</span><span class="o">=</span>float64<span class="o">}</span>
   <span class="m">1</span>.4%    <span class="m">69</span>.6%       <span class="m">0</span>.562s       <span class="m">2</span>.16e-05s     Py    <span class="m">26013</span>        <span class="m">3</span>   Gemv<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">1</span>.3%    <span class="m">70</span>.9%       <span class="m">0</span>.532s       <span class="m">9</span>.89e-07s     C     <span class="m">537602</span>       <span class="m">62</span>   Subtensor<span class="o">{</span>int64<span class="o">}</span>
   <span class="m">1</span>.3%    <span class="m">72</span>.2%       <span class="m">0</span>.528s       <span class="m">1</span>.45e-06s     C     <span class="m">364182</span>       <span class="m">42</span>   Reshape<span class="o">{</span><span class="m">3</span><span class="o">}</span>
   <span class="m">1</span>.2%    <span class="m">73</span>.4%       <span class="m">0</span>.476s       <span class="m">2</span>.74e-05s     Py    <span class="m">17342</span>        <span class="m">2</span>   AdvancedSubtensor
   <span class="m">1</span>.1%    <span class="m">74</span>.5%       <span class="m">0</span>.439s       <span class="m">3</span>.38e-06s     C     <span class="m">130065</span>       <span class="m">15</span>   Join
   ... <span class="o">(</span>remaining <span class="m">113</span> Ops account <span class="k">for</span>  <span class="m">25</span>.51%<span class="o">(</span><span class="m">10</span>.22s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
   <span class="m">2</span>.4%     <span class="m">2</span>.4%       <span class="m">0</span>.969s       <span class="m">1</span>.12e-04s   <span class="m">8671</span>   <span class="m">545</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;valid&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, True<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, False<span class="o">)}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2,3<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.4%     <span class="m">4</span>.8%       <span class="m">0</span>.958s       <span class="m">1</span>.11e-04s   <span class="m">8671</span>   <span class="m">543</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;valid&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, None<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, True<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, False<span class="o">)}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2,3<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.4%     <span class="m">7</span>.2%       <span class="m">0</span>.952s       <span class="m">1</span>.10e-04s   <span class="m">8671</span>   <span class="m">521</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;full&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, False<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, True<span class="o">)}(</span>AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.4%     <span class="m">9</span>.6%       <span class="m">0</span>.950s       <span class="m">1</span>.10e-04s   <span class="m">8671</span>   <span class="m">519</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;full&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, False<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">4</span>, <span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, True<span class="o">)}(</span>AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.9%    <span class="m">11</span>.4%       <span class="m">0</span>.753s       <span class="m">8</span>.68e-05s   <span class="m">8671</span>   <span class="m">441</span>   ConvOp<span class="o">{(</span><span class="s1">&#39;imshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;nkern&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;bsize&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dx&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;dy&#39;</span>, <span class="m">1</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;out_mode&#39;</span>, <span class="s1">&#39;valid&#39;</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_batch&#39;</span>, <span class="m">4</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_kern&#39;</span>, <span class="m">2</span><span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;unroll_patch&#39;</span>, False<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;imshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">255</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical&#39;</span>, <span class="o">(</span><span class="m">1</span>, <span class="m">128</span><span class="o">))</span>,<span class="o">(</span><span class="s1">&#39;kshp_logical_top_aligned&#39;</span>, True<span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, Elemwise<span class="o">{</span>mul,no_inplace<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.8%    <span class="m">13</span>.3%       <span class="m">0</span>.731s       <span class="m">8</span>.43e-05s   <span class="m">8671</span>   <span class="m">825</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.7%    <span class="m">15</span>.0%       <span class="m">0</span>.686s       <span class="m">7</span>.91e-05s   <span class="m">8671</span>   <span class="m">737</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.0%    <span class="m">16</span>.0%       <span class="m">0</span>.410s       <span class="m">4</span>.73e-05s   <span class="m">8671</span>   <span class="m">573</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">1</span>.0%    <span class="m">17</span>.0%       <span class="m">0</span>.396s       <span class="m">4</span>.57e-05s   <span class="m">8671</span>   <span class="m">893</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">0</span>.9%    <span class="m">17</span>.9%       <span class="m">0</span>.367s       <span class="m">4</span>.24e-05s   <span class="m">8671</span>   <span class="m">843</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">0</span>.9%    <span class="m">18</span>.8%       <span class="m">0</span>.357s       <span class="m">4</span>.12e-05s   <span class="m">8671</span>   <span class="m">224</span>   Gemv<span class="o">{</span>no_inplace<span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">}</span>, controller.W_in_and_reads_to_o_copy01.T, InplaceDimShuffle<span class="o">{</span><span class="m">1</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">19</span>.6%       <span class="m">0</span>.312s       <span class="m">3</span>.60e-05s   <span class="m">8671</span>   <span class="m">739</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">0</span>.8%    <span class="m">20</span>.3%       <span class="m">0</span>.304s       <span class="m">3</span>.51e-05s   <span class="m">8671</span>   <span class="m">527</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">21</span>.1%       <span class="m">0</span>.301s       <span class="m">3</span>.47e-05s   <span class="m">8671</span>   <span class="m">511</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">4</span>, <span class="m">4</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.7%    <span class="m">21</span>.8%       <span class="m">0</span>.297s       <span class="m">3</span>.43e-05s   <span class="m">8671</span>   <span class="m">601</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">0</span>.7%    <span class="m">22</span>.6%       <span class="m">0</span>.297s       <span class="m">3</span>.42e-05s   <span class="m">8671</span>   <span class="m">577</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>InplaceInc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">0</span>.7%    <span class="m">23</span>.3%       <span class="m">0</span>.295s       <span class="m">3</span>.41e-05s   <span class="m">8671</span>   <span class="m">992</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.7%    <span class="m">24</span>.1%       <span class="m">0</span>.295s       <span class="m">3</span>.40e-05s   <span class="m">8671</span>   <span class="m">736</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">0</span>.7%    <span class="m">24</span>.8%       <span class="m">0</span>.293s       <span class="m">3</span>.38e-05s   <span class="m">8671</span>   <span class="m">317</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">0</span>.7%    <span class="m">25</span>.5%       <span class="m">0</span>.291s       <span class="m">3</span>.36e-05s   <span class="m">8671</span>   <span class="m">991</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   ... <span class="o">(</span>remaining <span class="m">1069</span> Apply instances account <span class="k">for</span> <span class="m">74</span>.49%<span class="o">(</span><span class="m">29</span>.83s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and <span class="nb">set</span> the Theano flag lib.amdlibm<span class="o">=</span>True. This speeds up only some Elemwise operation.
</pre></div>


<p>以上の結果から、プログラムの速度を向上を図るために以下の２つの試みを行ってみた。</p>
<ol>
<li>Theano の blas 環境整備<ul>
<li>theano.tensor.blas.~ 系が <type> Py となっており、これは numpy を介して openblas を使用している？ようなのでこれの改良が可能？</li>
</ul>
</li>
<li>amdlibm のインストール<ul>
<li>上記の profile の最後にかかれているように、これにより Elemwise operation (20.5% とボトルネックの一つになっている) を改善できそう。</li>
</ul>
</li>
</ol>
<hr>
<h1>Blas environment setting</h1>
<h3>motivation</h3>
<p>上記の通り、theano.tensor.blas.~ 系が <type> Py となっている。<a href="https://groups.google.com/forum/#!searchin/theano-users/Gemv%7Csort:date/theano-users/UfPNnTI1pI4/2w48Gid_BwAJ">環境によっては同様の演算が <type> C で行われるらしく</a>、ググったところ<a href="https://groups.google.com/forum/#!topic/theano-users/9JdhCfp4YFM">これは theano の BLAS の設定に起因していそう</a>。  </p>
<p>そこで設定を以下のコマンドにより確認したところの出力が None だった (何も出力されない) ため、theano.config.blas.ldflags が設定されていないことがわかる。</p>
<div class="highlight"><pre><span></span>$ python -c <span class="s2">&quot;import theano; print(theano.config.blas.ldflags)&quot;</span>
</pre></div>


<p><a href="http://deeplearning.net/software/theano_versions/0.8.X/install_ubuntu.html">公式ドキュメント</a>によると (Speed test Theano/BLAS 参照) Theano は theano.config.blas.ldflags が未設定の場合 Numpy/Scipy を介して BLAS を利用するが、これにより生じるオーバーヘッドが今回の profile でボトルネックの１つとなっている theano.tensor.blas.Gemm や theano.tensor.blas.Dot において重要らしい。</p>
<p>ちなみに、使用している Numpy の blas は以下のように openblas だった。</p>
<div class="highlight"><pre><span></span>$ python -c <span class="s2">&quot;import numpy as np; print(np.__config__.show())&quot;</span>
lapack_opt_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;openblas&#39;</span>, <span class="s1">&#39;openblas&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/usr/local/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">language</span> <span class="o">=</span> c
blas_opt_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;openblas&#39;</span>, <span class="s1">&#39;openblas&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/usr/local/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">language</span> <span class="o">=</span> c
openblas_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;openblas&#39;</span>, <span class="s1">&#39;openblas&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/usr/local/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">language</span> <span class="o">=</span> c
blis_info:
  NOT AVAILABLE
openblas_lapack_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;openblas&#39;</span>, <span class="s1">&#39;openblas&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/usr/local/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">language</span> <span class="o">=</span> c
lapack_mkl_info:
  NOT AVAILABLE
blas_mkl_info:
  NOT AVAILABLE
None
</pre></div>


<p><a href="https://qiita.com/unnonouno/items/8ab453a1868d77a93679">Qiita の記事</a>によると openblas から <a href="https://software.intel.com/en-us/articles/getting-started-with-intel-optimized-theano">intel の mkl</a> へと変更することで Chainer の性能が約 1.5 になるらしいのでこれを blas として利用することにした。</p>
<h3>Install mkl (and setting new environment)</h3>
<p><a href="https://software.intel.com/en-us/mkl">intel のダウンロードサイト</a>の Free Download から簡単に個人情報登録し、mkl をダウンロードした。<br>
私の場合は l_mkl_2018.0.128.tgz というファイルがダウンロードされ、これを Ubuntu 上で展開した。<br>
後は l_mkl_2018.0.128/install.sh を走らせると対話型のインストールが行えるため、流れに沿っていれば良い。</p>
<p>なお、ユーザアカウントでこれを行った場合、root ユーザとしてインストールをする (システム上の全ユーザが使えるようにする) かローカル環境にダウンロードするか選べるが、前者の場合は /opt/ 以下に、後者の場合は ~/ 以下にそれぞれ intel/ というディレクトリが作られ、その下にインストールが行われる。</p>
<p>...と、ここまで mkl インストールしてきたが、<a href="http://deeplearning.net/software/theano/install_ubuntu.html">Theanoの公式</a>に mkl を使う場合 conda を使って環境設定を行えば良いと書いてあるので、今まで pip を使用して作っていた環境を conda を利用して作ることにした。 </p>
<p>conda を用い、以下のコマンドを入力。</p>
<div class="highlight"><pre><span></span>$ conda install numpy scipy mkl
</pre></div>


<p>すると以下のエラーが出た。</p>
<div class="highlight"><pre><span></span>ERROR conda.core.link:_execute_actions<span class="o">(</span><span class="m">337</span><span class="o">)</span>: An error occurred <span class="k">while</span> installing package <span class="s1">&#39;defaults::numpy-1.13.3-py27hbcc08e0_0&#39;</span>.
CondaError: Cannot link a <span class="nb">source</span> that does not exist. /home/guchio/miniconda2/pkgs/numpy-1.13.3-py27hbcc08e0_0/bin/f2py
Attempting to roll back.


CondaError: Cannot link a <span class="nb">source</span> that does not exist. /home/guchio/miniconda2/pkgs/numpy-1.13.3-py27hbcc08e0_0/bin/f2py
</pre></div>


<p>そこで<a href="https://github.com/conda/conda/issues/6078">ここ</a>を参考に、以下を行ったところ解決。</p>
<div class="highlight"><pre><span></span>$ conda clean --all
$ conda update conda
$ conda update --all
</pre></div>


<p>これで以下のように conda 上に mkl を利用する numpy の実行環境が完成。  </p>
<div class="highlight"><pre><span></span>$ python -c <span class="s2">&quot;import numpy as np; print(np.__config__.show())&quot;</span>
lapack_opt_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;mkl_rt&#39;</span>, <span class="s1">&#39;pthread&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;SCIPY_MKL_H&#39;</span>, None<span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">include_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/include&#39;</span><span class="o">]</span>
blas_opt_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;mkl_rt&#39;</span>, <span class="s1">&#39;pthread&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;SCIPY_MKL_H&#39;</span>, None<span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">include_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/include&#39;</span><span class="o">]</span>
lapack_mkl_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;mkl_rt&#39;</span>, <span class="s1">&#39;pthread&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;SCIPY_MKL_H&#39;</span>, None<span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">include_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/include&#39;</span><span class="o">]</span>
blas_mkl_info:
    <span class="nv">libraries</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;mkl_rt&#39;</span>, <span class="s1">&#39;pthread&#39;</span><span class="o">]</span>
    <span class="nv">library_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/lib&#39;</span><span class="o">]</span>
    <span class="nv">define_macros</span> <span class="o">=</span> <span class="o">[(</span><span class="s1">&#39;SCIPY_MKL_H&#39;</span>, None<span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;HAVE_CBLAS&#39;</span>, None<span class="o">)]</span>
    <span class="nv">include_dirs</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;/home/guchio/miniconda2/envs/ntmenv-owl/include&#39;</span><span class="o">]</span>
None
</pre></div>


<p>そこで、openblas を利用した場合と mkl を利用した場合の速度テストを以下のコードによって行ってみた。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4000000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4000000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">))</span>

<span class="n">before_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">after_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">after_time</span> <span class="o">-</span> <span class="n">before_time</span><span class="p">)</span>
</pre></div>


<p>結果は openblas を利用するものが 25.502314、mkl を利用するものが 21.625779 となった。</p>
<p>次に Theano も以下のように入れ直し、無事成功。</p>
<div class="highlight"><pre><span></span>$ conda install <span class="nv">theano</span><span class="o">=</span><span class="m">0</span>.8.2
$ python -c <span class="s2">&quot;import theano; print(theano.config.blas.ldflags)&quot;</span>
-L/home/guchio/miniconda2/envs/ntmenv-owl/lib -lmkl_rt -lpthread -lm -lm
</pre></div>


<p>Theano の速度テストをしてみる。</p>
<div class="highlight"><pre><span></span>$ python <span class="sb">`</span>python -c <span class="s2">&quot;import os, theano; print(os.path.dirname(theano.__file__))&quot;</span><span class="sb">`</span>/misc/check_blas.py
</pre></div>


<p>結果は numpy 経由で openblas を利用するものが 11.99s、mkl を利用するものが 11.32s となった。<br>
正直あまり変わらない...</p>
<h3>Result</h3>
<p>環境も整ったので profiling してみた。以下が結果。</p>
<div class="highlight"><pre><span></span>Function <span class="nv">profiling</span>
<span class="o">==================</span>
  Message: examples/run_tasks.py:376
  Time in <span class="m">100</span> calls to Function.__call__: <span class="m">4</span>.939490e+01s
  Time in Function.fn.__call__: <span class="m">4</span>.933104e+01s <span class="o">(</span><span class="m">99</span>.871%<span class="o">)</span>
  Time in thunks: <span class="m">4</span>.895610e+01s <span class="o">(</span><span class="m">99</span>.112%<span class="o">)</span>
  Total compile time: <span class="m">1</span>.077718e+03s
    Number of Apply nodes: <span class="m">1288</span>
    Theano Optimizer time: <span class="m">1</span>.013889e+03s
       Theano validate time: <span class="m">3</span>.349193e+00s
    Theano Linker <span class="nb">time</span> <span class="o">(</span>includes C, CUDA code generation/compiling<span class="o">)</span>: <span class="m">5</span>.913572e+01s
       Import <span class="nb">time</span> <span class="m">7</span>.540491e-01s

Time in all call to theano.grad<span class="o">()</span> <span class="m">3</span>.068751e+01s
Time since theano import <span class="m">1184</span>.741s
Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">98</span>.9%    <span class="m">98</span>.9%      <span class="m">48</span>.411s       <span class="m">2</span>.42e-01s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.scan_module.scan_op.Scan
   <span class="m">0</span>.5%    <span class="m">99</span>.4%       <span class="m">0</span>.260s       <span class="m">3</span>.79e-06s     C    <span class="m">68500</span>     <span class="m">685</span>   theano.tensor.elemwise.Elemwise
   <span class="m">0</span>.2%    <span class="m">99</span>.6%       <span class="m">0</span>.076s       <span class="m">7</span>.57e-05s     C     <span class="m">1000</span>      <span class="m">10</span>   theano.tensor.blas.Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.7%       <span class="m">0</span>.056s       <span class="m">7</span>.38e-06s     C     <span class="m">7600</span>      <span class="m">76</span>   theano.tensor.basic.Alloc
   <span class="m">0</span>.1%    <span class="m">99</span>.7%       <span class="m">0</span>.031s       <span class="m">3</span>.08e-04s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxWithBias
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.016s       <span class="m">5</span>.26e-05s     C      <span class="m">300</span>       <span class="m">3</span>   theano.tensor.blas.Gemm
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.013s       <span class="m">7</span>.60e-07s     C    <span class="m">17300</span>     <span class="m">173</span>   theano.compile.ops.Shape_i
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.012s       <span class="m">1</span>.52e-05s     C      <span class="m">800</span>       <span class="m">8</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.012s       <span class="m">9</span>.10e-06s     C     <span class="m">1300</span>      <span class="m">13</span>   theano.tensor.basic.Join
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.011s       <span class="m">2</span>.94e-06s     C     <span class="m">3600</span>      <span class="m">36</span>   theano.tensor.basic.Reshape
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.009s       <span class="m">4</span>.69e-05s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.009s       <span class="m">1</span>.15e-06s     C     <span class="m">7500</span>      <span class="m">75</span>   theano.tensor.subtensor.Subtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.008s       <span class="m">1</span>.09e-06s     C     <span class="m">7100</span>      <span class="m">71</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.007s       <span class="m">7</span>.10e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.007s       <span class="m">8</span>.76e-07s     C     <span class="m">7700</span>      <span class="m">77</span>   theano.tensor.opt.MakeVector
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.005s       <span class="m">4</span>.84e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.basic.Nonzero
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.004s       <span class="m">3</span>.68e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxGrad
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">1</span>.59e-05s     C      <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor1
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">7</span>.57e-06s     C      <span class="m">400</span>       <span class="m">4</span>   theano.tensor.elemwise.Sum
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.001s       <span class="m">1</span>.35e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.compile.ops.DeepCopyOp
   ... <span class="o">(</span>remaining <span class="m">5</span> Classes account <span class="k">for</span>   <span class="m">0</span>.01%<span class="o">(</span><span class="m">0</span>.00s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
  <span class="m">89</span>.8%    <span class="m">89</span>.8%      <span class="m">43</span>.985s       <span class="m">4</span>.40e-01s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}</span>
   <span class="m">9</span>.0%    <span class="m">98</span>.9%       <span class="m">4</span>.426s       <span class="m">4</span>.43e-02s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,scan_fn<span class="o">}</span>
   <span class="m">0</span>.2%    <span class="m">99</span>.0%       <span class="m">0</span>.076s       <span class="m">7</span>.57e-05s     C     <span class="m">1000</span>       <span class="m">10</span>   Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.2%       <span class="m">0</span>.056s       <span class="m">7</span>.38e-06s     C     <span class="m">7600</span>       <span class="m">76</span>   Alloc
   <span class="m">0</span>.1%    <span class="m">99</span>.2%       <span class="m">0</span>.034s       <span class="m">5</span>.62e-06s     C     <span class="m">6000</span>       <span class="m">60</span>   Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.031s       <span class="m">3</span>.08e-04s     C      <span class="m">100</span>        <span class="m">1</span>   SoftmaxWithBias
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.030s       <span class="m">2</span>.68e-06s     C     <span class="m">11300</span>      <span class="m">113</span>   Elemwise<span class="o">{</span>Add<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.4%       <span class="m">0</span>.029s       <span class="m">4</span>.97e-06s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.5%       <span class="m">0</span>.026s       <span class="m">4</span>.39e-06s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.5%       <span class="m">0</span>.023s       <span class="m">3</span>.25e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.021s       <span class="m">2</span>.07e-04s     C      <span class="m">100</span>        <span class="m">1</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.020s       <span class="m">2</span>.91e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.019s       <span class="m">3</span>.04e-06s     C     <span class="m">6200</span>       <span class="m">62</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.016s       <span class="m">5</span>.26e-05s     C      <span class="m">300</span>        <span class="m">3</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.012s       <span class="m">1</span>.48e-05s     C      <span class="m">800</span>        <span class="m">8</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.012s       <span class="m">9</span>.10e-06s     C     <span class="m">1300</span>       <span class="m">13</span>   Join
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.010s       <span class="m">3</span>.52e-06s     C     <span class="m">2700</span>       <span class="m">27</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.009s       <span class="m">4</span>.69e-05s     Py     <span class="m">200</span>        <span class="m">2</span>   AdvancedSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.008s       <span class="m">8</span>.38e-05s     C      <span class="m">100</span>        <span class="m">1</span>   IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>:int64:<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.008s       <span class="m">7</span>.00e-06s     C     <span class="m">1100</span>       <span class="m">11</span>   Elemwise<span class="o">{</span>clip,no_inplace<span class="o">}</span>
   ... <span class="o">(</span>remaining <span class="m">109</span> Ops account <span class="k">for</span>   <span class="m">0</span>.22%<span class="o">(</span><span class="m">0</span>.11s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
  <span class="m">89</span>.8%    <span class="m">89</span>.8%      <span class="m">43</span>.985s       <span class="m">4</span>.40e-01s    <span class="m">100</span>   <span class="m">783</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2,3,x<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int6
   <span class="m">9</span>.0%    <span class="m">98</span>.9%       <span class="m">4</span>.426s       <span class="m">4</span>.43e-02s    <span class="m">100</span>   <span class="m">688</span>   forall_inplace,cpu,scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>.0, Subtensor<span class="o">{</span>int64:int64:int8<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, controller.W_in_and_reads_to_o01, controller.W_hid_to_o01, controller.W_in_and_reads_to_i01, controller.W_hid_to_i01, controller.W_in_and_rea
   <span class="m">0</span>.1%    <span class="m">99</span>.0%       <span class="m">0</span>.031s       <span class="m">3</span>.08e-04s    <span class="m">100</span>   <span class="m">723</span>   SoftmaxWithBias<span class="o">(</span>Dot22.0, output_modality_net.b<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.021s       <span class="m">2</span>.07e-04s    <span class="m">100</span>   <span class="m">733</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}(</span>Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.012s       <span class="m">1</span>.17e-04s    <span class="m">100</span>   <span class="m">907</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.011s       <span class="m">1</span>.14e-04s    <span class="m">100</span>   <span class="m">491</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.011s       <span class="m">1</span>.12e-04s    <span class="m">100</span>   <span class="m">487</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.011s       <span class="m">1</span>.08e-04s    <span class="m">100</span>   <span class="m">716</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, output_modality_net.W<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.010s       <span class="m">9</span>.90e-05s    <span class="m">100</span>   <span class="m">912</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.009s       <span class="m">9</span>.39e-05s    <span class="m">100</span>   <span class="m">765</span>   Dot22<span class="o">(</span>SoftmaxGrad.0, output_modality_net.W.T<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.008s       <span class="m">8</span>.38e-05s    <span class="m">100</span>   <span class="m">918</span>   IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>:int64:<span class="o">}(</span>Alloc.0, Subtensor<span class="o">{</span>::int64<span class="o">}</span>.0, ScalarFromTensor.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.008s       <span class="m">8</span>.29e-05s    <span class="m">100</span>   <span class="m">764</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, SoftmaxGrad.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.007s       <span class="m">7</span>.10e-05s    <span class="m">100</span>   <span class="m">755</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>Alloc.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>-i0<span class="o">)</span> / i1<span class="o">)}}</span>.0, Subtensor<span class="o">{</span>int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.007s       <span class="m">6</span>.69e-05s    <span class="m">100</span>   <span class="m">1236</span>   Gemm<span class="o">{</span>inplace<span class="o">}(</span>Alloc.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span>.0<span class="o">})</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.006s       <span class="m">6</span>.18e-05s    <span class="m">100</span>   <span class="m">914</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.006s       <span class="m">6</span>.09e-05s    <span class="m">100</span>   <span class="m">916</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.006s       <span class="m">5</span>.89e-05s    <span class="m">100</span>    <span class="m">74</span>   Join<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, read0.read0.shift.W, read1.read1.shift.W, read2.read2.shift.W, read3.read3.shift.W<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.005s       <span class="m">5</span>.18e-05s    <span class="m">100</span>   <span class="m">1257</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i0 * i1 * sgn<span class="o">(</span>i2<span class="o">)))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.2%       <span class="m">0</span>.005s       <span class="m">5</span>.01e-05s    <span class="m">100</span>   <span class="m">431</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.3%       <span class="m">0</span>.005s       <span class="m">4</span>.90e-05s    <span class="m">100</span>   <span class="m">441</span>   AdvancedSubtensor<span class="o">(</span>Reshape<span class="o">{</span><span class="m">3</span><span class="o">}</span>.0, Subtensor<span class="o">{</span>int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64<span class="o">}</span>.0<span class="o">)</span>
   ... <span class="o">(</span>remaining <span class="m">1268</span> Apply instances account <span class="k">for</span> <span class="m">0</span>.75%<span class="o">(</span><span class="m">0</span>.37s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and <span class="nb">set</span> the Theano flag lib.amdlibm<span class="o">=</span>True. This speeds up only some Elemwise operation.
</pre></div>


<p>また、grad_of_scan_fn は以下のようになった。</p>
<div class="highlight"><pre><span></span>Scan Op profiling <span class="o">(</span> grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn <span class="o">)</span>
<span class="o">==================</span>
  Message: None
  Time in <span class="m">100</span> calls of the op <span class="o">(</span><span class="k">for</span> a total of <span class="m">8680</span> steps<span class="o">)</span> <span class="m">4</span>.361261e+01s

  Total <span class="nb">time</span> spent in calling the VM <span class="m">4</span>.090440e+01s <span class="o">(</span><span class="m">93</span>.790%<span class="o">)</span>
  Total overhead <span class="o">(</span>computing slices..<span class="o">)</span> <span class="m">2</span>.708209e+00s <span class="o">(</span><span class="m">6</span>.210%<span class="o">)</span>

Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">26</span>.9%    <span class="m">26</span>.9%       <span class="m">9</span>.692s       <span class="m">2</span>.86e-06s     C   <span class="m">3393880</span>     <span class="m">391</span>   theano.tensor.elemwise.Elemwise
  <span class="m">15</span>.3%    <span class="m">42</span>.2%       <span class="m">5</span>.517s       <span class="m">3</span>.97e-05s     Py  <span class="m">138880</span>      <span class="m">16</span>   theano.tensor.basic.Split
   <span class="m">8</span>.1%    <span class="m">50</span>.3%       <span class="m">2</span>.925s       <span class="m">6</span>.74e-06s     C   <span class="m">434000</span>      <span class="m">50</span>   theano.tensor.blas.Dot22
   <span class="m">7</span>.5%    <span class="m">57</span>.8%       <span class="m">2</span>.686s       <span class="m">7</span>.74e-05s     C    <span class="m">34720</span>       <span class="m">4</span>   theano.tensor.nnet.corr.CorrMM_gradInputs
   <span class="m">5</span>.6%    <span class="m">63</span>.4%       <span class="m">2</span>.031s       <span class="m">5</span>.85e-05s     C    <span class="m">34720</span>       <span class="m">4</span>   theano.tensor.nnet.corr.CorrMM_gradWeights
   <span class="m">3</span>.8%    <span class="m">67</span>.2%       <span class="m">1</span>.371s       <span class="m">2</span>.47e-06s     C   <span class="m">555520</span>      <span class="m">64</span>   theano.tensor.elemwise.Sum
   <span class="m">3</span>.6%    <span class="m">70</span>.8%       <span class="m">1</span>.293s       <span class="m">3</span>.72e-05s     Py   <span class="m">34720</span>       <span class="m">4</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">3</span>.3%    <span class="m">74</span>.1%       <span class="m">1</span>.202s       <span class="m">1</span>.08e-06s     C   <span class="m">1111040</span>     <span class="m">128</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">3</span>.3%    <span class="m">77</span>.4%       <span class="m">1</span>.195s       <span class="m">1</span>.22e-06s     C   <span class="m">980840</span>     <span class="m">113</span>   theano.tensor.basic.Reshape
   <span class="m">2</span>.7%    <span class="m">80</span>.2%       <span class="m">0</span>.984s       <span class="m">5</span>.67e-05s     C    <span class="m">17360</span>       <span class="m">2</span>   theano.tensor.nnet.corr.CorrMM
   <span class="m">2</span>.4%    <span class="m">82</span>.6%       <span class="m">0</span>.874s       <span class="m">6</span>.71e-06s     C   <span class="m">130200</span>      <span class="m">15</span>   theano.tensor.blas.BatchedDot
   <span class="m">1</span>.8%    <span class="m">84</span>.3%       <span class="m">0</span>.631s       <span class="m">9</span>.09e-06s     C    <span class="m">69440</span>       <span class="m">8</span>   theano.tensor.blas_c.CGemv
   <span class="m">1</span>.7%    <span class="m">86</span>.1%       <span class="m">0</span>.631s       <span class="m">1</span>.04e-06s     C   <span class="m">607600</span>      <span class="m">70</span>   theano.tensor.subtensor.Subtensor
   <span class="m">1</span>.7%    <span class="m">87</span>.8%       <span class="m">0</span>.625s       <span class="m">3</span>.60e-05s     Py   <span class="m">17360</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">1</span>.7%    <span class="m">89</span>.5%       <span class="m">0</span>.618s       <span class="m">8</span>.91e-06s     C    <span class="m">69440</span>       <span class="m">8</span>   theano.tensor.blas.Dot22Scalar
   <span class="m">1</span>.5%    <span class="m">91</span>.0%       <span class="m">0</span>.532s       <span class="m">1</span>.53e-05s     C    <span class="m">34720</span>       <span class="m">4</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">1</span>.5%    <span class="m">92</span>.5%       <span class="m">0</span>.532s       <span class="m">1</span>.02e-05s     C    <span class="m">52080</span>       <span class="m">6</span>   theano.tensor.blas.Gemm
   <span class="m">1</span>.3%    <span class="m">93</span>.8%       <span class="m">0</span>.464s       <span class="m">3</span>.56e-06s     C   <span class="m">130200</span>      <span class="m">15</span>   theano.tensor.basic.Join
   <span class="m">1</span>.1%    <span class="m">94</span>.9%       <span class="m">0</span>.406s       <span class="m">2</span>.34e-05s     Py   <span class="m">17360</span>       <span class="m">2</span>   theano.tensor.basic.ARange
   <span class="m">1</span>.0%    <span class="m">95</span>.9%       <span class="m">0</span>.364s       <span class="m">1</span>.05e-05s     C    <span class="m">34720</span>       <span class="m">4</span>   theano.tensor.nnet.nnet.Softmax
   ... <span class="o">(</span>remaining <span class="m">10</span> Classes account <span class="k">for</span>   <span class="m">4</span>.09%<span class="o">(</span><span class="m">1</span>.48s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
   <span class="m">9</span>.1%     <span class="m">9</span>.1%       <span class="m">3</span>.277s       <span class="m">3</span>.78e-05s     Py    <span class="m">86800</span>       <span class="m">10</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}</span>
   <span class="m">8</span>.1%    <span class="m">17</span>.2%       <span class="m">2</span>.925s       <span class="m">6</span>.74e-06s     C     <span class="m">434000</span>       <span class="m">50</span>   Dot22
   <span class="m">7</span>.5%    <span class="m">24</span>.7%       <span class="m">2</span>.686s       <span class="m">7</span>.74e-05s     C     <span class="m">34720</span>        <span class="m">4</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">6</span>.2%    <span class="m">30</span>.9%       <span class="m">2</span>.240s       <span class="m">4</span>.30e-05s     Py    <span class="m">52080</span>        <span class="m">6</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">5</span>.9%    <span class="m">36</span>.8%       <span class="m">2</span>.125s       <span class="m">2</span>.95e-06s     C     <span class="m">720440</span>       <span class="m">83</span>   Elemwise<span class="o">{</span>mul,no_inplace<span class="o">}</span>
   <span class="m">5</span>.6%    <span class="m">42</span>.4%       <span class="m">2</span>.031s       <span class="m">5</span>.85e-05s     C     <span class="m">34720</span>        <span class="m">4</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">4</span>.9%    <span class="m">47</span>.3%       <span class="m">1</span>.774s       <span class="m">2</span>.49e-06s     C     <span class="m">711760</span>       <span class="m">82</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">3</span>.6%    <span class="m">50</span>.9%       <span class="m">1</span>.293s       <span class="m">3</span>.72e-05s     Py    <span class="m">34720</span>        <span class="m">4</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>
   <span class="m">2</span>.7%    <span class="m">53</span>.6%       <span class="m">0</span>.984s       <span class="m">5</span>.67e-05s     C     <span class="m">17360</span>        <span class="m">2</span>   CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">2</span>.4%    <span class="m">56</span>.1%       <span class="m">0</span>.874s       <span class="m">6</span>.71e-06s     C     <span class="m">130200</span>       <span class="m">15</span>   BatchedDot
   <span class="m">2</span>.0%    <span class="m">58</span>.0%       <span class="m">0</span>.705s       <span class="m">1</span>.14e-06s     C     <span class="m">616280</span>       <span class="m">71</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">1</span>.8%    <span class="m">59</span>.8%       <span class="m">0</span>.635s       <span class="m">2</span>.22e-06s     C     <span class="m">286440</span>       <span class="m">33</span>   Sum<span class="o">{</span><span class="nv">axis</span><span class="o">=[</span><span class="m">2</span><span class="o">]</span>, <span class="nv">acc_dtype</span><span class="o">=</span>float64<span class="o">}</span>
   <span class="m">1</span>.7%    <span class="m">61</span>.5%       <span class="m">0</span>.625s       <span class="m">3</span>.60e-05s     Py    <span class="m">17360</span>        <span class="m">2</span>   AdvancedSubtensor
   <span class="m">1</span>.7%    <span class="m">63</span>.2%       <span class="m">0</span>.618s       <span class="m">8</span>.91e-06s     C     <span class="m">69440</span>        <span class="m">8</span>   Dot22Scalar
   <span class="m">1</span>.5%    <span class="m">64</span>.7%       <span class="m">0</span>.532s       <span class="m">1</span>.02e-05s     C     <span class="m">52080</span>        <span class="m">6</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">1</span>.4%    <span class="m">66</span>.1%       <span class="m">0</span>.504s       <span class="m">9</span>.36e-07s     C     <span class="m">538160</span>       <span class="m">62</span>   Subtensor<span class="o">{</span>int64<span class="o">}</span>
   <span class="m">1</span>.4%    <span class="m">67</span>.5%       <span class="m">0</span>.490s       <span class="m">1</span>.35e-06s     C     <span class="m">364560</span>       <span class="m">42</span>   Reshape<span class="o">{</span><span class="m">3</span><span class="o">}</span>
   <span class="m">1</span>.3%    <span class="m">68</span>.7%       <span class="m">0</span>.464s       <span class="m">3</span>.56e-06s     C     <span class="m">130200</span>       <span class="m">15</span>   Join
   <span class="m">1</span>.2%    <span class="m">70</span>.0%       <span class="m">0</span>.441s       <span class="m">1</span>.69e-05s     C     <span class="m">26040</span>        <span class="m">3</span>   Elemwise<span class="o">{</span>pow<span class="o">}</span>
   <span class="m">1</span>.1%    <span class="m">71</span>.1%       <span class="m">0</span>.406s       <span class="m">2</span>.34e-05s     Py    <span class="m">17360</span>        <span class="m">2</span>   ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>
   ... <span class="o">(</span>remaining <span class="m">107</span> Ops account <span class="k">for</span>  <span class="m">28</span>.90%<span class="o">(</span><span class="m">10</span>.42s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
    ------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
   <span class="m">2</span>.8%     <span class="m">2</span>.8%       <span class="m">1</span>.027s       <span class="m">1</span>.18e-04s   <span class="m">8680</span>   <span class="m">514</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.8%     <span class="m">5</span>.7%       <span class="m">1</span>.019s       <span class="m">1</span>.17e-04s   <span class="m">8680</span>   <span class="m">516</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.3%     <span class="m">7</span>.9%       <span class="m">0</span>.819s       <span class="m">9</span>.44e-05s   <span class="m">8680</span>   <span class="m">515</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.3%    <span class="m">10</span>.2%       <span class="m">0</span>.815s       <span class="m">9</span>.39e-05s   <span class="m">8680</span>   <span class="m">517</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.1%    <span class="m">12</span>.3%       <span class="m">0</span>.756s       <span class="m">8</span>.71e-05s   <span class="m">8680</span>   <span class="m">440</span>   CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.0%    <span class="m">14</span>.3%       <span class="m">0</span>.726s       <span class="m">8</span>.37e-05s   <span class="m">8680</span>   <span class="m">736</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.3%    <span class="m">15</span>.6%       <span class="m">0</span>.473s       <span class="m">5</span>.45e-05s   <span class="m">8680</span>   <span class="m">583</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">1</span>.3%    <span class="m">16</span>.9%       <span class="m">0</span>.457s       <span class="m">5</span>.27e-05s   <span class="m">8680</span>   <span class="m">836</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.3%    <span class="m">18</span>.2%       <span class="m">0</span>.451s       <span class="m">5</span>.20e-05s   <span class="m">8680</span>   <span class="m">521</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">1</span>.2%    <span class="m">19</span>.4%       <span class="m">0</span>.450s       <span class="m">5</span>.19e-05s   <span class="m">8680</span>   <span class="m">966</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.1%    <span class="m">20</span>.5%       <span class="m">0</span>.406s       <span class="m">4</span>.68e-05s   <span class="m">8680</span>   <span class="m">443</span>   AdvancedSubtensor<span class="o">(</span>CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">1</span>.1%    <span class="m">21</span>.7%       <span class="m">0</span>.406s       <span class="m">4</span>.67e-05s   <span class="m">8680</span>   <span class="m">552</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">1</span>.1%    <span class="m">22</span>.7%       <span class="m">0</span>.395s       <span class="m">4</span>.55e-05s   <span class="m">8680</span>   <span class="m">877</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.0%    <span class="m">23</span>.7%       <span class="m">0</span>.352s       <span class="m">4</span>.05e-05s   <span class="m">8680</span>   <span class="m">967</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.0%    <span class="m">24</span>.7%       <span class="m">0</span>.345s       <span class="m">3</span>.98e-05s   <span class="m">8680</span>   <span class="m">531</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.9%    <span class="m">25</span>.6%       <span class="m">0</span>.314s       <span class="m">3</span>.62e-05s   <span class="m">8680</span>   <span class="m">663</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.8%    <span class="m">26</span>.4%       <span class="m">0</span>.295s       <span class="m">3</span>.40e-05s   <span class="m">8680</span>   <span class="m">533</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.8%    <span class="m">27</span>.2%       <span class="m">0</span>.290s       <span class="m">3</span>.34e-05s   <span class="m">8680</span>   <span class="m">506</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">4</span>, <span class="m">4</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">28</span>.0%       <span class="m">0</span>.287s       <span class="m">3</span>.31e-05s   <span class="m">8680</span>   <span class="m">507</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">4</span>, <span class="m">4</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">28</span>.8%       <span class="m">0</span>.281s       <span class="m">3</span>.23e-05s   <span class="m">8680</span>   <span class="m">592</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>InplaceInc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   ... <span class="o">(</span>remaining <span class="m">1044</span> Apply instances account <span class="k">for</span> <span class="m">71</span>.25%<span class="o">(</span><span class="m">25</span>.68s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and <span class="nb">set</span> the Theano flag lib.amdlibm<span class="o">=</span>True. This speeds up only some Elemwise operation.
</pre></div>


<p>上記の通り、theano.tensor.blas.~ 系が <type> C となっており、Time in 100 calls to Function.<strong>call</strong> が 5.591766e+01s から 4.939490e+01s になっている。
一応速度を 0.883 倍にできたっぽい。</p>
<h1>Install amdlibm</h1>
<p>Profile の結果に散々書かれているように、amdlibm を使うと elemwise 演算の速度向上が期待できるっぽい。</p>
<p>そこで、amdlibm を<a href="http://developer.amd.com/amd-cpu-libraries/amd-math-library-libm/">ここ</a>からダウンロードし、<a href="https://hvasbath.github.io/beat/installation.html">ここ</a>を参考にインストールした。</p>
<p>その後の profile 結果は以下の通り。</p>
<div class="highlight"><pre><span></span>Function <span class="nv">profiling</span>
<span class="o">==================</span>
  Message: examples/run_tasks.py:376
  Time in <span class="m">100</span> calls to Function.__call__: <span class="m">4</span>.898488e+01s
  Time in Function.fn.__call__: <span class="m">4</span>.892176e+01s <span class="o">(</span><span class="m">99</span>.871%<span class="o">)</span>
  Time in thunks: <span class="m">4</span>.854884e+01s <span class="o">(</span><span class="m">99</span>.110%<span class="o">)</span>
  Total compile time: <span class="m">9</span>.918714e+02s
    Number of Apply nodes: <span class="m">1288</span>
    Theano Optimizer time: <span class="m">9</span>.340450e+02s
       Theano validate time: <span class="m">1</span>.014861e+01s
    Theano Linker <span class="nb">time</span> <span class="o">(</span>includes C, CUDA code generation/compiling<span class="o">)</span>: <span class="m">5</span>.377673e+01s
       Import <span class="nb">time</span> <span class="m">6</span>.545787e-01s

Time in all call to theano.grad<span class="o">()</span> <span class="m">2</span>.948562e+01s
Time since theano import <span class="m">1094</span>.254s
Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">98</span>.6%    <span class="m">98</span>.6%      <span class="m">47</span>.865s       <span class="m">2</span>.39e-01s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.scan_module.scan_op.Scan
   <span class="m">0</span>.9%    <span class="m">99</span>.5%       <span class="m">0</span>.421s       <span class="m">6</span>.14e-06s     C    <span class="m">68500</span>     <span class="m">685</span>   theano.tensor.elemwise.Elemwise
   <span class="m">0</span>.2%    <span class="m">99</span>.6%       <span class="m">0</span>.078s       <span class="m">7</span>.83e-05s     C     <span class="m">1000</span>      <span class="m">10</span>   theano.tensor.blas.Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.7%       <span class="m">0</span>.055s       <span class="m">7</span>.25e-06s     C     <span class="m">7600</span>      <span class="m">76</span>   theano.tensor.basic.Alloc
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.017s       <span class="m">5</span>.74e-05s     C      <span class="m">300</span>       <span class="m">3</span>   theano.tensor.blas.Gemm
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.013s       <span class="m">7</span>.57e-07s     C    <span class="m">17300</span>     <span class="m">173</span>   theano.compile.ops.Shape_i
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.012s       <span class="m">1</span>.47e-05s     C      <span class="m">800</span>       <span class="m">8</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.012s       <span class="m">8</span>.85e-06s     C     <span class="m">1300</span>      <span class="m">13</span>   theano.tensor.basic.Join
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.010s       <span class="m">2</span>.86e-06s     C     <span class="m">3600</span>      <span class="m">36</span>   theano.tensor.basic.Reshape
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.009s       <span class="m">1</span>.17e-06s     C     <span class="m">7500</span>      <span class="m">75</span>   theano.tensor.subtensor.Subtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.008s       <span class="m">4</span>.09e-05s     Py     <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.008s       <span class="m">8</span>.03e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxWithBias
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.008s       <span class="m">1</span>.07e-06s     C     <span class="m">7100</span>      <span class="m">71</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">0</span>.0%    <span class="m">99</span>.9%       <span class="m">0</span>.007s       <span class="m">6</span>.79e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.007s       <span class="m">8</span>.55e-07s     C     <span class="m">7700</span>      <span class="m">77</span>   theano.tensor.opt.MakeVector
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.004s       <span class="m">4</span>.45e-05s     Py     <span class="m">100</span>       <span class="m">1</span>   theano.tensor.basic.Nonzero
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.004s       <span class="m">3</span>.84e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.tensor.nnet.nnet.SoftmaxGrad
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">7</span>.90e-06s     C      <span class="m">400</span>       <span class="m">4</span>   theano.tensor.elemwise.Sum
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.003s       <span class="m">1</span>.55e-05s     C      <span class="m">200</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor1
   <span class="m">0</span>.0%   <span class="m">100</span>.0%       <span class="m">0</span>.001s       <span class="m">1</span>.34e-05s     C      <span class="m">100</span>       <span class="m">1</span>   theano.compile.ops.DeepCopyOp
   ... <span class="o">(</span>remaining <span class="m">5</span> Classes account <span class="k">for</span>   <span class="m">0</span>.01%<span class="o">(</span><span class="m">0</span>.00s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
  <span class="m">89</span>.9%    <span class="m">89</span>.9%      <span class="m">43</span>.644s       <span class="m">4</span>.36e-01s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}</span>
   <span class="m">8</span>.7%    <span class="m">98</span>.6%       <span class="m">4</span>.222s       <span class="m">4</span>.22e-02s     Py     <span class="m">100</span>        <span class="m">1</span>   forall_inplace,cpu,scan_fn<span class="o">}</span>
   <span class="m">0</span>.3%    <span class="m">98</span>.9%       <span class="m">0</span>.139s       <span class="m">2</span>.35e-05s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.2%    <span class="m">99</span>.0%       <span class="m">0</span>.078s       <span class="m">7</span>.83e-05s     C     <span class="m">1000</span>       <span class="m">10</span>   Dot22
   <span class="m">0</span>.1%    <span class="m">99</span>.2%       <span class="m">0</span>.055s       <span class="m">7</span>.25e-06s     C     <span class="m">7600</span>       <span class="m">76</span>   Alloc
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.053s       <span class="m">6</span>.62e-05s     C      <span class="m">800</span>        <span class="m">8</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.3%       <span class="m">0</span>.034s       <span class="m">5</span>.71e-06s     C     <span class="m">6000</span>       <span class="m">60</span>   Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.4%       <span class="m">0</span>.031s       <span class="m">2</span>.74e-06s     C     <span class="m">11300</span>      <span class="m">113</span>   Elemwise<span class="o">{</span>Add<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>
   <span class="m">0</span>.1%    <span class="m">99</span>.4%       <span class="m">0</span>.026s       <span class="m">4</span>.34e-06s     C     <span class="m">5900</span>       <span class="m">59</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.5%       <span class="m">0</span>.022s       <span class="m">3</span>.07e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.5%       <span class="m">0</span>.021s       <span class="m">2</span>.95e-06s     C     <span class="m">7000</span>       <span class="m">70</span>   Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.020s       <span class="m">2</span>.01e-04s     C      <span class="m">100</span>        <span class="m">1</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.6%       <span class="m">0</span>.020s       <span class="m">3</span>.18e-06s     C     <span class="m">6200</span>       <span class="m">62</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.017s       <span class="m">5</span>.74e-05s     C      <span class="m">300</span>        <span class="m">3</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.013s       <span class="m">6</span>.44e-05s     C      <span class="m">200</span>        <span class="m">2</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">3</span><span class="o">)]</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.012s       <span class="m">8</span>.85e-06s     C     <span class="m">1300</span>       <span class="m">13</span>   Join
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.009s       <span class="m">3</span>.45e-06s     C     <span class="m">2700</span>       <span class="m">27</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.7%       <span class="m">0</span>.009s       <span class="m">8</span>.57e-05s     C      <span class="m">100</span>        <span class="m">1</span>   IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>:int64:<span class="o">}</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.008s       <span class="m">4</span>.09e-05s     Py     <span class="m">200</span>        <span class="m">2</span>   AdvancedSubtensor
   <span class="m">0</span>.0%    <span class="m">99</span>.8%       <span class="m">0</span>.008s       <span class="m">7</span>.36e-06s     C     <span class="m">1100</span>       <span class="m">11</span>   Elemwise<span class="o">{</span>clip,no_inplace<span class="o">}</span>
   ... <span class="o">(</span>remaining <span class="m">109</span> Ops account <span class="k">for</span>   <span class="m">0</span>.23%<span class="o">(</span><span class="m">0</span>.11s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
  <span class="m">89</span>.9%    <span class="m">89</span>.9%      <span class="m">43</span>.644s       <span class="m">4</span>.36e-01s    <span class="m">100</span>   <span class="m">783</span>   forall_inplace,cpu,grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,3,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2<span class="o">}</span>.0, InplaceDimShuffle<span class="o">{</span><span class="m">0</span>,1,2,3,x<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0, Subtensor<span class="o">{</span>int64:int6
   <span class="m">8</span>.7%    <span class="m">98</span>.6%       <span class="m">4</span>.222s       <span class="m">4</span>.22e-02s    <span class="m">100</span>   <span class="m">688</span>   forall_inplace,cpu,scan_fn<span class="o">}(</span>Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, <span class="o">((</span>i2 * i3<span class="o">)</span> // <span class="o">(</span>i4 * i0<span class="o">))</span>, i0<span class="o">)}}</span>.0, Subtensor<span class="o">{</span>int64:int64:int8<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, IncSubtensor<span class="o">{</span>InplaceSet<span class="p">;</span>:int64:<span class="o">}</span>.0, controller.W_in_and_reads_to_o01, controller.W_hid_to_o01, controller.W_in_and_reads_to_i01, controller.W_hid_to_i01, controller.W_in_and_rea
   <span class="m">0</span>.0%    <span class="m">98</span>.6%       <span class="m">0</span>.020s       <span class="m">2</span>.01e-04s    <span class="m">100</span>   <span class="m">733</span>   Elemwise<span class="o">{</span>sqr,no_inplace<span class="o">}(</span>Subtensor<span class="o">{</span>int64:int64:int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.7%       <span class="m">0</span>.019s       <span class="m">1</span>.93e-04s    <span class="m">100</span>   <span class="m">776</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>clip,no_inplace<span class="o">}</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.7%       <span class="m">0</span>.016s       <span class="m">1</span>.58e-04s    <span class="m">100</span>   <span class="m">1234</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.7%       <span class="m">0</span>.016s       <span class="m">1</span>.58e-04s    <span class="m">100</span>   <span class="m">1048</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, 3D<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.8%       <span class="m">0</span>.013s       <span class="m">1</span>.28e-04s    <span class="m">100</span>   <span class="m">1069</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, 3D<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.8%       <span class="m">0</span>.013s       <span class="m">1</span>.27e-04s    <span class="m">100</span>   <span class="m">1059</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, 3D<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.8%       <span class="m">0</span>.013s       <span class="m">1</span>.27e-04s    <span class="m">100</span>   <span class="m">1079</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, 3D<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.8%       <span class="m">0</span>.013s       <span class="m">1</span>.27e-04s    <span class="m">100</span>   <span class="m">1240</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">3</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.9%       <span class="m">0</span>.013s       <span class="m">1</span>.26e-04s    <span class="m">100</span>   <span class="m">1093</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, 3D<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.9%       <span class="m">0</span>.013s       <span class="m">1</span>.26e-04s    <span class="m">100</span>   <span class="m">1241</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.9%       <span class="m">0</span>.013s       <span class="m">1</span>.26e-04s    <span class="m">100</span>   <span class="m">1242</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">98</span>.9%       <span class="m">0</span>.012s       <span class="m">1</span>.21e-04s    <span class="m">100</span>   <span class="m">907</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.011s       <span class="m">1</span>.12e-04s    <span class="m">100</span>   <span class="m">716</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, output_modality_net.W<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.011s       <span class="m">1</span>.11e-04s    <span class="m">100</span>   <span class="m">487</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.011s       <span class="m">1</span>.10e-04s    <span class="m">100</span>   <span class="m">491</span>   Alloc<span class="o">(</span>TensorConstant<span class="o">{</span><span class="m">0</span>.0<span class="o">}</span>, Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{</span>Switch<span class="o">(</span>EQ<span class="o">(</span>i0, i1<span class="o">)</span>, i2, i0<span class="o">)}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.0%       <span class="m">0</span>.011s       <span class="m">1</span>.10e-04s    <span class="m">100</span>   <span class="m">912</span>   Dot22<span class="o">(</span>Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.010s       <span class="m">9</span>.90e-05s    <span class="m">100</span>   <span class="m">1269</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   <span class="m">0</span>.0%    <span class="m">99</span>.1%       <span class="m">0</span>.010s       <span class="m">9</span>.89e-05s    <span class="m">100</span>   <span class="m">1270</span>   Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> - <span class="o">((</span>i2 * i3<span class="o">)</span> / sqrt<span class="o">((</span>i2 + i4 + i5 + sqr<span class="o">(</span>i6<span class="o">)))))}}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)](</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.9<span class="o">}</span>, &lt;TensorType<span class="o">(</span>float32, matrix<span class="o">)</span>&gt;, TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)</span> of <span class="m">0</span>.0001<span class="o">}</span>, Elemwise<span class="o">{</span>Clip<span class="o">}[(</span><span class="m">0</span>, <span class="m">0</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Mul<span class="o">}[(</span><span class="m">0</span>, <span class="m">1</span><span class="o">)]</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{(</span>i0 * sqr<span class="o">(</span>i1<span class="o">))}}</span>.0, Elemwise<span class="o">{</span>Composite<span class="o">{((</span>i0 * i1<span class="o">)</span> + <span class="o">(</span>i2 * i3<span class="o">))}}</span>.0<span class="o">)</span>
   ... <span class="o">(</span>remaining <span class="m">1268</span> Apply instances account <span class="k">for</span> <span class="m">0</span>.92%<span class="o">(</span><span class="m">0</span>.45s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip <span class="k">for</span> today.
</pre></div>


<p>また、grad_of_scan_fn は以下の通り。</p>
<div class="highlight"><pre><span></span>Scan Op profiling <span class="o">(</span> grad_of_scan_fn<span class="p">&amp;</span>grad_of_scan_fn <span class="o">)</span>
<span class="o">==================</span>
  Message: None
  Time in <span class="m">100</span> calls of the op <span class="o">(</span><span class="k">for</span> a total of <span class="m">8700</span> steps<span class="o">)</span> <span class="m">4</span>.326865e+01s

  Total <span class="nb">time</span> spent in calling the VM <span class="m">4</span>.045974e+01s <span class="o">(</span><span class="m">93</span>.508%<span class="o">)</span>
  Total overhead <span class="o">(</span>computing slices..<span class="o">)</span> <span class="m">2</span>.808916e+00s <span class="o">(</span><span class="m">6</span>.492%<span class="o">)</span>

Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Class name&gt;</span>
  <span class="m">25</span>.5%    <span class="m">25</span>.5%       <span class="m">9</span>.022s       <span class="m">2</span>.65e-06s     C   <span class="m">3401700</span>     <span class="m">391</span>   theano.tensor.elemwise.Elemwise
  <span class="m">16</span>.3%    <span class="m">41</span>.7%       <span class="m">5</span>.757s       <span class="m">4</span>.14e-05s     Py  <span class="m">139200</span>      <span class="m">16</span>   theano.tensor.basic.Split
   <span class="m">8</span>.4%    <span class="m">50</span>.1%       <span class="m">2</span>.958s       <span class="m">6</span>.80e-06s     C   <span class="m">435000</span>      <span class="m">50</span>   theano.tensor.blas.Dot22
   <span class="m">7</span>.4%    <span class="m">57</span>.5%       <span class="m">2</span>.615s       <span class="m">7</span>.52e-05s     C    <span class="m">34800</span>       <span class="m">4</span>   theano.tensor.nnet.corr.CorrMM_gradInputs
   <span class="m">5</span>.7%    <span class="m">63</span>.1%       <span class="m">2</span>.007s       <span class="m">5</span>.77e-05s     C    <span class="m">34800</span>       <span class="m">4</span>   theano.tensor.nnet.corr.CorrMM_gradWeights
   <span class="m">4</span>.0%    <span class="m">67</span>.1%       <span class="m">1</span>.401s       <span class="m">2</span>.52e-06s     C   <span class="m">556800</span>      <span class="m">64</span>   theano.tensor.elemwise.Sum
   <span class="m">3</span>.7%    <span class="m">70</span>.8%       <span class="m">1</span>.312s       <span class="m">3</span>.77e-05s     Py   <span class="m">34800</span>       <span class="m">4</span>   theano.tensor.subtensor.AdvancedIncSubtensor
   <span class="m">3</span>.6%    <span class="m">74</span>.4%       <span class="m">1</span>.264s       <span class="m">1</span>.13e-06s     C   <span class="m">1113600</span>     <span class="m">128</span>   theano.tensor.elemwise.DimShuffle
   <span class="m">3</span>.5%    <span class="m">77</span>.9%       <span class="m">1</span>.235s       <span class="m">1</span>.26e-06s     C   <span class="m">983100</span>     <span class="m">113</span>   theano.tensor.basic.Reshape
   <span class="m">2</span>.8%    <span class="m">80</span>.6%       <span class="m">0</span>.984s       <span class="m">5</span>.65e-05s     C    <span class="m">17400</span>       <span class="m">2</span>   theano.tensor.nnet.corr.CorrMM
   <span class="m">2</span>.3%    <span class="m">82</span>.9%       <span class="m">0</span>.820s       <span class="m">6</span>.28e-06s     C   <span class="m">130500</span>      <span class="m">15</span>   theano.tensor.blas.BatchedDot
   <span class="m">1</span>.8%    <span class="m">84</span>.8%       <span class="m">0</span>.650s       <span class="m">9</span>.33e-06s     C    <span class="m">69600</span>       <span class="m">8</span>   theano.tensor.blas.Dot22Scalar
   <span class="m">1</span>.8%    <span class="m">86</span>.6%       <span class="m">0</span>.644s       <span class="m">1</span>.06e-06s     C   <span class="m">609000</span>      <span class="m">70</span>   theano.tensor.subtensor.Subtensor
   <span class="m">1</span>.7%    <span class="m">88</span>.4%       <span class="m">0</span>.620s       <span class="m">3</span>.56e-05s     Py   <span class="m">17400</span>       <span class="m">2</span>   theano.tensor.subtensor.AdvancedSubtensor
   <span class="m">1</span>.7%    <span class="m">90</span>.0%       <span class="m">0</span>.600s       <span class="m">8</span>.63e-06s     C    <span class="m">69600</span>       <span class="m">8</span>   theano.tensor.blas_c.CGemv
   <span class="m">1</span>.5%    <span class="m">91</span>.5%       <span class="m">0</span>.531s       <span class="m">1</span>.02e-05s     C    <span class="m">52200</span>       <span class="m">6</span>   theano.tensor.blas.Gemm
   <span class="m">1</span>.3%    <span class="m">92</span>.9%       <span class="m">0</span>.477s       <span class="m">3</span>.66e-06s     C   <span class="m">130500</span>      <span class="m">15</span>   theano.tensor.basic.Join
   <span class="m">1</span>.3%    <span class="m">94</span>.2%       <span class="m">0</span>.464s       <span class="m">1</span>.33e-05s     C    <span class="m">34800</span>       <span class="m">4</span>   theano.tensor.subtensor.IncSubtensor
   <span class="m">1</span>.1%    <span class="m">95</span>.3%       <span class="m">0</span>.383s       <span class="m">2</span>.20e-05s     Py   <span class="m">17400</span>       <span class="m">2</span>   theano.tensor.basic.ARange
   <span class="m">1</span>.0%    <span class="m">96</span>.2%       <span class="m">0</span>.342s       <span class="m">9</span>.36e-07s     C   <span class="m">365400</span>      <span class="m">42</span>   theano.compile.ops.Shape_i
   ... <span class="o">(</span>remaining <span class="m">10</span> Classes account <span class="k">for</span>   <span class="m">3</span>.75%<span class="o">(</span><span class="m">1</span>.33s<span class="o">)</span> of the runtime<span class="o">)</span>

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;type&gt; &lt;<span class="c1">#call&gt; &lt;#apply&gt; &lt;Op name&gt;</span>
   <span class="m">9</span>.6%     <span class="m">9</span>.6%       <span class="m">3</span>.413s       <span class="m">3</span>.92e-05s     Py    <span class="m">87000</span>       <span class="m">10</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}</span>
   <span class="m">8</span>.4%    <span class="m">18</span>.0%       <span class="m">2</span>.958s       <span class="m">6</span>.80e-06s     C     <span class="m">435000</span>       <span class="m">50</span>   Dot22
   <span class="m">7</span>.4%    <span class="m">25</span>.4%       <span class="m">2</span>.615s       <span class="m">7</span>.52e-05s     C     <span class="m">34800</span>        <span class="m">4</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">6</span>.6%    <span class="m">32</span>.0%       <span class="m">2</span>.344s       <span class="m">4</span>.49e-05s     Py    <span class="m">52200</span>        <span class="m">6</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">5</span>.8%    <span class="m">37</span>.7%       <span class="m">2</span>.038s       <span class="m">2</span>.82e-06s     C     <span class="m">722100</span>       <span class="m">83</span>   Elemwise<span class="o">{</span>mul,no_inplace<span class="o">}</span>
   <span class="m">5</span>.7%    <span class="m">43</span>.4%       <span class="m">2</span>.007s       <span class="m">5</span>.77e-05s     C     <span class="m">34800</span>        <span class="m">4</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">4</span>.9%    <span class="m">48</span>.3%       <span class="m">1</span>.736s       <span class="m">2</span>.43e-06s     C     <span class="m">713400</span>       <span class="m">82</span>   Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>
   <span class="m">3</span>.7%    <span class="m">52</span>.0%       <span class="m">1</span>.312s       <span class="m">3</span>.77e-05s     Py    <span class="m">34800</span>        <span class="m">4</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>
   <span class="m">2</span>.8%    <span class="m">54</span>.8%       <span class="m">0</span>.984s       <span class="m">5</span>.65e-05s     C     <span class="m">17400</span>        <span class="m">2</span>   CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>
   <span class="m">2</span>.3%    <span class="m">57</span>.1%       <span class="m">0</span>.820s       <span class="m">6</span>.28e-06s     C     <span class="m">130500</span>       <span class="m">15</span>   BatchedDot
   <span class="m">2</span>.1%    <span class="m">59</span>.2%       <span class="m">0</span>.726s       <span class="m">1</span>.18e-06s     C     <span class="m">617700</span>       <span class="m">71</span>   Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>
   <span class="m">1</span>.8%    <span class="m">61</span>.0%       <span class="m">0</span>.650s       <span class="m">9</span>.33e-06s     C     <span class="m">69600</span>        <span class="m">8</span>   Dot22Scalar
   <span class="m">1</span>.8%    <span class="m">62</span>.8%       <span class="m">0</span>.644s       <span class="m">2</span>.24e-06s     C     <span class="m">287100</span>       <span class="m">33</span>   Sum<span class="o">{</span><span class="nv">axis</span><span class="o">=[</span><span class="m">2</span><span class="o">]</span>, <span class="nv">acc_dtype</span><span class="o">=</span>float64<span class="o">}</span>
   <span class="m">1</span>.7%    <span class="m">64</span>.6%       <span class="m">0</span>.620s       <span class="m">3</span>.56e-05s     Py    <span class="m">17400</span>        <span class="m">2</span>   AdvancedSubtensor
   <span class="m">1</span>.5%    <span class="m">66</span>.1%       <span class="m">0</span>.531s       <span class="m">1</span>.02e-05s     C     <span class="m">52200</span>        <span class="m">6</span>   Gemm<span class="o">{</span>inplace<span class="o">}</span>
   <span class="m">1</span>.5%    <span class="m">67</span>.5%       <span class="m">0</span>.516s       <span class="m">9</span>.56e-07s     C     <span class="m">539400</span>       <span class="m">62</span>   Subtensor<span class="o">{</span>int64<span class="o">}</span>
   <span class="m">1</span>.4%    <span class="m">69</span>.0%       <span class="m">0</span>.509s       <span class="m">1</span>.39e-06s     C     <span class="m">365400</span>       <span class="m">42</span>   Reshape<span class="o">{</span><span class="m">3</span><span class="o">}</span>
   <span class="m">1</span>.3%    <span class="m">70</span>.3%       <span class="m">0</span>.477s       <span class="m">3</span>.66e-06s     C     <span class="m">130500</span>       <span class="m">15</span>   Join
   <span class="m">1</span>.1%    <span class="m">71</span>.4%       <span class="m">0</span>.391s       <span class="m">2</span>.25e-06s     C     <span class="m">174000</span>       <span class="m">20</span>   Sum<span class="o">{</span><span class="nv">axis</span><span class="o">=[</span><span class="m">0</span><span class="o">]</span>, <span class="nv">acc_dtype</span><span class="o">=</span>float64<span class="o">}</span>
   <span class="m">1</span>.1%    <span class="m">72</span>.5%       <span class="m">0</span>.383s       <span class="m">2</span>.20e-05s     Py    <span class="m">17400</span>        <span class="m">2</span>   ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>
   ... <span class="o">(</span>remaining <span class="m">107</span> Ops account <span class="k">for</span>  <span class="m">27</span>.51%<span class="o">(</span><span class="m">9</span>.74s<span class="o">)</span> of the runtime<span class="o">)</span>

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;<span class="nb">time</span> per call&gt; &lt;<span class="c1">#call&gt; &lt;id&gt; &lt;Apply name&gt;</span>
   <span class="m">2</span>.8%     <span class="m">2</span>.8%       <span class="m">0</span>.993s       <span class="m">1</span>.14e-04s   <span class="m">8700</span>   <span class="m">516</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.8%     <span class="m">5</span>.6%       <span class="m">0</span>.993s       <span class="m">1</span>.14e-04s   <span class="m">8700</span>   <span class="m">514</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.3%     <span class="m">7</span>.9%       <span class="m">0</span>.813s       <span class="m">9</span>.34e-05s   <span class="m">8700</span>   <span class="m">515</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.3%    <span class="m">10</span>.2%       <span class="m">0</span>.807s       <span class="m">9</span>.28e-05s   <span class="m">8700</span>   <span class="m">517</span>   CorrMM_gradWeights<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.1%    <span class="m">12</span>.3%       <span class="m">0</span>.758s       <span class="m">8</span>.71e-05s   <span class="m">8700</span>   <span class="m">440</span>   CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::, :int64:<span class="o">}</span>.0, Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">2</span>.1%    <span class="m">14</span>.4%       <span class="m">0</span>.742s       <span class="m">8</span>.53e-05s   <span class="m">8700</span>   <span class="m">736</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.4%    <span class="m">15</span>.8%       <span class="m">0</span>.485s       <span class="m">5</span>.57e-05s   <span class="m">8700</span>   <span class="m">966</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.3%    <span class="m">17</span>.1%       <span class="m">0</span>.476s       <span class="m">5</span>.47e-05s   <span class="m">8700</span>   <span class="m">583</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">1</span>.3%    <span class="m">18</span>.5%       <span class="m">0</span>.475s       <span class="m">5</span>.46e-05s   <span class="m">8700</span>   <span class="m">836</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.2%    <span class="m">19</span>.7%       <span class="m">0</span>.433s       <span class="m">4</span>.98e-05s   <span class="m">8700</span>   <span class="m">521</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">1</span>, <span class="m">1</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">1</span>.2%    <span class="m">20</span>.9%       <span class="m">0</span>.418s       <span class="m">4</span>.81e-05s   <span class="m">8700</span>   <span class="m">552</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>Inc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">1</span>.2%    <span class="m">22</span>.0%       <span class="m">0</span>.415s       <span class="m">4</span>.77e-05s   <span class="m">8700</span>   <span class="m">877</span>   Split<span class="o">{</span><span class="m">4</span><span class="o">}(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0,2<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, &lt;TensorType<span class="o">(</span>int64, vector<span class="o">)</span>&gt;<span class="o">)</span>
   <span class="m">1</span>.1%    <span class="m">23</span>.2%       <span class="m">0</span>.397s       <span class="m">4</span>.56e-05s   <span class="m">8700</span>   <span class="m">443</span>   AdvancedSubtensor<span class="o">(</span>CorrMM<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">1</span>.1%    <span class="m">24</span>.2%       <span class="m">0</span>.377s       <span class="m">4</span>.33e-05s   <span class="m">8700</span>   <span class="m">967</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>Elemwise<span class="o">{</span>add,no_inplace<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">1</span><span class="o">}</span>, MakeVector<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">1</span>.0%    <span class="m">25</span>.2%       <span class="m">0</span>.342s       <span class="m">3</span>.93e-05s   <span class="m">8700</span>   <span class="m">531</span>   CorrMM_gradInputs<span class="o">{</span>valid, <span class="o">(</span><span class="m">1</span>, <span class="m">1</span><span class="o">)}(</span>Subtensor<span class="o">{</span>::, ::, ::int64, ::int64<span class="o">}</span>.0, AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.9%    <span class="m">26</span>.1%       <span class="m">0</span>.316s       <span class="m">3</span>.63e-05s   <span class="m">8700</span>   <span class="m">663</span>   Dot22<span class="o">(</span>InplaceDimShuffle<span class="o">{</span><span class="m">1</span>,0<span class="o">}</span>.0, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0<span class="o">)</span>
   <span class="m">0</span>.9%    <span class="m">27</span>.0%       <span class="m">0</span>.304s       <span class="m">3</span>.50e-05s   <span class="m">8700</span>   <span class="m">506</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">4</span>, <span class="m">4</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">27</span>.8%       <span class="m">0</span>.298s       <span class="m">3</span>.42e-05s   <span class="m">8700</span>   <span class="m">592</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>InplaceInc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">28</span>.6%       <span class="m">0</span>.290s       <span class="m">3</span>.34e-05s   <span class="m">8700</span>   <span class="m">507</span>   AdvancedIncSubtensor<span class="o">{</span><span class="nv">inplace</span><span class="o">=</span>False,  <span class="nv">set_instead_of_inc</span><span class="o">=</span>False<span class="o">}(</span>TensorConstant<span class="o">{(</span><span class="m">4</span>, <span class="m">4</span>, <span class="m">1</span>, ..28<span class="o">)</span> of <span class="m">0</span>.0<span class="o">}</span>, Reshape<span class="o">{</span><span class="m">2</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, ARange<span class="o">{</span><span class="nv">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">0</span><span class="o">}</span>, SliceConstant<span class="o">{</span>None, None, None<span class="o">})</span>
   <span class="m">0</span>.8%    <span class="m">29</span>.4%       <span class="m">0</span>.290s       <span class="m">3</span>.33e-05s   <span class="m">8700</span>   <span class="m">556</span>   Split<span class="o">{</span><span class="m">2</span><span class="o">}(</span>IncSubtensor<span class="o">{</span>InplaceInc<span class="p">;</span>::, ::, ::, :int64:<span class="o">}</span>.0, TensorConstant<span class="o">{</span><span class="m">3</span><span class="o">}</span>, TensorConstant<span class="o">{(</span><span class="m">2</span>,<span class="o">)</span> of <span class="m">128</span><span class="o">})</span>
   ... <span class="o">(</span>remaining <span class="m">1044</span> Apply instances account <span class="k">for</span> <span class="m">70</span>.57%<span class="o">(</span><span class="m">24</span>.99s<span class="o">)</span> of the runtime<span class="o">)</span>

Here are tips to potentially make your code run faster
                 <span class="o">(</span><span class="k">if</span> you think of new ones, suggest them on the mailing list<span class="o">)</span>.
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip <span class="k">for</span> today.
</pre></div>


<p>結果確かに elemwise の演算は早くなっており、最終的に Time in 100 calls to Function.<strong>call</strong> を 4.898488e+01s (最初の 0.876 倍) にできた。</p>
                </div>
                <footer class="text-right">
                    <p>- guchio3</p>
                </footer>
            </div>
        </div>
    </article>
</section>
<footer>
    <hr>
    <div class="row">
        <div class="col-lg-9 text-center">
            <p><small>
                Built by <a href="http://docs.getpelican.com/en/latest">Pelican</a> / <a href="https://github.com/ingwinlu/pelican-twitchy">pelican-twitchy</a>
                &middot;                    &copy; 2017 guchio3
            </small></p>
        </div>
    </div>
</footer>            </div>
        </div>
        <!-- /#page-content-wrapper -->
    </div>
    <!-- /#wrapper -->
    <!-- jQuery Version 1.11.2 -->
    <script src="/theme/js/jquery-1.11.2.min.js"></script>
    <!-- Bootstrap Core JavaScript -->
    <script src="/theme/js/bootstrap.min.js"></script>
    <!-- twitchy Script -->
    <script src="/theme/js/pelican_twitchy.min.js"></script>

</body>
</html>